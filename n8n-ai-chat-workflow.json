{
  "name": "AI Chat Workflow with Callback",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-chat-webhook",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "d4c8f9a1-2b3e-4d5f-a6b7-8c9d0e1f2a3b",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "webhookId": "ai-chat-webhook"
    },
    {
      "parameters": {
        "keepOnlySet": false,
        "values": {
          "string": [
            {
              "name": "correlation_id",
              "value": "={{$json.correlation_id}}"
            },
            {
              "name": "user_id",
              "value": "={{$json.user_id}}"
            },
            {
              "name": "message",
              "value": "={{$json.message}}"
            },
            {
              "name": "callback_url",
              "value": "={{$json.callback_url}}"
            },
            {
              "name": "timestamp",
              "value": "={{$json.timestamp}}"
            }
          ]
        },
        "options": {}
      },
      "id": "b5e6f7a8-3c4d-5e6f-b7c8-9d0a1b2c3d4e",
      "name": "Extract Request Data",
      "type": "n8n-nodes-base.set",
      "typeVersion": 2,
      "position": [450, 300]
    },
    {
      "parameters": {
        "content": "## AI Processing Placeholder\n\nThis is where you would add your AI processing nodes:\n- OpenAI ChatGPT\n- Claude API\n- Local LLM\n- Or any other AI service\n\nFor testing, we'll simulate an AI response.",
        "height": 200,
        "width": 300
      },
      "id": "ai-placeholder",
      "name": "AI Processing Note",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [650, 100]
    },
    {
      "parameters": {
        "functionCode": "// Simulate AI processing\n// In production, replace this with actual AI service call\n\nconst userMessage = $input.item.json.message;\nconst correlationId = $input.item.json.correlation_id;\n\n// Simulate processing delay\nawait new Promise(resolve => setTimeout(resolve, 1000));\n\n// Generate simulated response\nconst responses = [\n  `I understand you said: \"${userMessage}\". This is a test response from the n8n workflow.`,\n  `Processing your request: \"${userMessage}\". The workflow is working correctly!`,\n  `Thank you for your message: \"${userMessage}\". The async communication is functioning properly.`,\n  `Received: \"${userMessage}\". This demonstrates the full flow from React → FastAPI → n8n → FastAPI → React.`\n];\n\nconst response = responses[Math.floor(Math.random() * responses.length)];\n\n// Add some analysis\nconst analysis = {\n  messageLength: userMessage.length,\n  wordCount: userMessage.split(' ').length,\n  sentiment: userMessage.includes('!') ? 'excited' : 'neutral',\n  processingTime: '1.2s'\n};\n\nreturn {\n  correlation_id: correlationId,\n  user_id: $input.item.json.user_id,\n  original_message: userMessage,\n  ai_response: response,\n  analysis: analysis,\n  processed_at: new Date().toISOString()\n};"
      },
      "id": "c6f7g8a9-4d5e-6f7g-c8d9-0e1a2b3c4d5f",
      "name": "Simulate AI Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [650, 300]
    },
    {
      "parameters": {
        "url": "={{$node[\"Extract Request Data\"].json.callback_url}}",
        "authentication": "none",
        "method": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"correlation_id\": \"={{$json.correlation_id}}\",\n  \"user_id\": \"={{$json.user_id}}\",\n  \"result\": \"{{$json.ai_response}}\\n\\n**Analysis:**\\n- Message length: {{$json.analysis.messageLength}} characters\\n- Word count: {{$json.analysis.wordCount}} words\\n- Sentiment: {{$json.analysis.sentiment}}\\n- Processing time: {{$json.analysis.processingTime}}\"\n}",
        "options": {
          "timeout": 10000,
          "batching": {
            "batch": {
              "batchSize": 1
            }
          }
        }
      },
      "id": "d7a8b9c0-5e6f-7a8b-d9e0-1f2a3b4c5d6e",
      "name": "Send Callback to FastAPI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [850, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": {
          "success": true,
          "correlation_id": "={{$node[\"Extract Request Data\"].json.correlation_id}}",
          "message": "Workflow processing initiated",
          "timestamp": "={{$now.toISO()}}"
        },
        "options": {}
      },
      "id": "e8b9c0d1-6f7a-8b9c-e0f1-2a3b4c5d6e7f",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1050, 300]
    },
    {
      "parameters": {
        "url": "={{$node[\"Extract Request Data\"].json.callback_url}}",
        "authentication": "none",
        "method": "POST",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"correlation_id\": \"={{$node[\"Extract Request Data\"].json.correlation_id}}\",\n  \"user_id\": \"={{$node[\"Extract Request Data\"].json.user_id}}\",\n  \"error\": \"Failed to process request: {{$json.error.message}}\"\n}",
        "options": {
          "timeout": 5000
        }
      },
      "id": "error-callback",
      "name": "Send Error Callback",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [850, 500],
      "notesInFlow": false,
      "disabled": false
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Extract Request Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Request Data": {
      "main": [
        [
          {
            "node": "Simulate AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simulate AI Response": {
      "main": [
        [
          {
            "node": "Send Callback to FastAPI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send Callback to FastAPI": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Send Error Callback",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "f9a8b7c6-5d4e-3c2b-1a0f-9e8d7c6b5a4f",
  "id": "ai-chat-workflow",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "n8n-instance"
  },
  "tags": []
}